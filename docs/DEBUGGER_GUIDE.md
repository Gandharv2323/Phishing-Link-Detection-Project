# üîç HSEF Model Debugger - Complete Documentation

## Overview

The HSEF Debugger provides comprehensive analysis of URL classification decisions, helping you understand:
- Why a URL was classified a certain way
- Which features influenced the decision
- How base models and meta-layer contributed
- Why misclassifications occurred and how to fix them

---

## ‚úÖ What's Included

### üìä Analysis Components

1. **Base Model Predictions**
   - Individual predictions from Random Forest, XGBoost, and SVM
   - Confidence scores for each model
   - Class probabilities for all 5 classes

2. **Meta-Layer Fusion Analysis**
   - Contribution weights for each base model
   - Relative importance percentages
   - How the final decision was made

3. **SHAP Feature Importance**
   - Top 10 most influential features
   - Feature values and their impact direction
   - Features categorized by domain (Lexical, Structural, Entropy, Semantic)

4. **Misclassification Analysis** (when actual class is provided)
   - Base model agreement analysis
   - Probability gaps
   - Corrective insights and recommendations

5. **Visualizations**
   - 4-panel comprehensive analysis plot
   - Base model comparison bars
   - Meta-layer contribution chart
   - Class probability distribution
   - SHAP feature importance plot

6. **Reports**
   - JSON detailed report with all metrics
   - CSV summary for easy analysis
   - Aggregate batch summaries

---

## üöÄ Installation & Setup

### Prerequisites

```bash
# Already installed if you ran quick_setup.py
# Otherwise:
pip install numpy pandas matplotlib seaborn scikit-learn xgboost shap joblib
```

### Quick Check

```python
python example_debugger.py
```

This will:
- ‚úÖ Analyze a single URL
- ‚úÖ Analyze a batch of 10 URLs
- ‚úÖ Find and explain misclassifications
- ‚úÖ Generate all visualizations

---

## üìñ Usage Guide

### 1Ô∏è‚É£ Analyze Single URL

```python
from hsef_debugger import analyze_url
import pandas as pd

# Load your data
df = pd.read_csv('All.csv')
row = df.iloc[0]

# Extract features and actual class
features = row.drop('URL_Type_obf_Type')
actual_class = row['URL_Type_obf_Type']

# Analyze
result = analyze_url(
    url_features=features,
    url_name="suspicious_url",
    actual_class=actual_class  # Optional
)

# Access results
print(f"Predicted: {result['predicted_class']}")
print(f"Confidence: {result['confidence']:.2%}")
print(f"Base models: {result['base_models']}")
```

### 2Ô∏è‚É£ Analyze Batch from CSV

```python
from hsef_debugger import analyze_csv

# Analyze all URLs in CSV
results = analyze_csv('test_batch.csv')

# Filter misclassifications
misclassified = [r for r in results 
                 if r.get('misclassification_analysis', {}).get('is_misclassified')]

print(f"Found {len(misclassified)} misclassifications")
```

### 3Ô∏è‚É£ Advanced Usage

```python
from hsef_debugger import HSEFDebugger

# Create debugger instance
debugger = HSEFDebugger(
    models_dir='models',
    output_dir='my_debug_results'
)

# Analyze with custom options
result = debugger.analyze_url(
    url_features=features,
    url_name="example",
    actual_class="benign"
)

# Access detailed information
print("Base Model Predictions:")
for model, pred in result['base_models'].items():
    print(f"  {model}: {pred['predicted_class']} ({pred['confidence']:.2%})")

print("\nMeta-Layer Contributions:")
for model, contrib in result['meta_layer']['predicted_class_contributions'].items():
    print(f"  {model}: {contrib:+.4f}")

print("\nTop SHAP Features:")
for feat in result['shap_analysis']['top_features'][:5]:
    print(f"  {feat['feature']}: {feat['shap_value']:+.6f}")
```

---

## üìä Output Files

### Generated for Each URL:

1. **`debug_analysis_[url]_[timestamp].png`**
   - 4-panel visualization with all metrics
   - High-resolution (150 DPI)
   - Ready for presentations

2. **`debug_report_[url]_[timestamp].json`**
   - Complete analysis in JSON format
   - All probabilities and contributions
   - SHAP values and insights

3. **`debug_summary_[url]_[timestamp].csv`**
   - Quick summary in CSV format
   - Base model predictions
   - All class probabilities

### For Batch Analysis:

4. **`aggregate_summary_[timestamp].csv`**
   - Summary of all URLs
   - Misclassification statistics
   - Base model agreement rates

---

## üéØ Understanding the Output

### Base Model Predictions

Shows what each model predicted independently:

```
Random Forest:
  Predicted: spam
  Confidence: 99.52%
  Top 3 classes:
    spam           : 99.52%
    phishing       :  0.35%
    malware        :  0.08%
```

**Interpretation:**
- Green bars = agrees with final prediction
- Red bars = disagrees with final prediction
- Higher confidence = more certain

### Meta-Layer Contributions

Shows how much each model influenced the final decision:

```
Contributions to predicted class 'spam':
  Random Forest  : +0.3421
  XGBoost        : +0.4182
  SVM            : +0.2156

Relative importance:
  Random Forest  :  35.4%
  XGBoost        :  43.2%
  SVM            :  21.4%
```

**Interpretation:**
- Positive values = pushed toward this class
- Larger absolute values = stronger influence
- Percentages show relative importance

### SHAP Feature Importance

Top features that drove the decision:

```
Feature                        Value      SHAP Impact  Direction
urlLen                         87.00      +0.012453    ‚Üí spam
NumberofDotsinURL              3.00       +0.008721    ‚Üí spam
NumDash                        2.00       -0.005432    ‚Üê away
```

**Interpretation:**
- Positive SHAP = feature increased probability of predicted class
- Negative SHAP = feature decreased probability of predicted class
- Larger absolute value = stronger influence

### Misclassification Insights

When wrong, provides actionable insights:

```
‚úó MISCLASSIFICATION DETECTED
  Actual: benign
  Predicted: phishing
  Confidence: 87.43%

  Probability for actual class 'benign': 8.21%
  Difference: 79.22%

  Base models agreeing with wrong prediction: 2/3
    - Random Forest
    - XGBoost

  Corrective Insights:
    1. Majority of base models wrong - check feature engineering
    2. HIGH CONFIDENCE misclassification - strong systematic error
    3. ‚Üí Consider: rebalancing training data or feature selection
    4. Top influencing feature: urlLen = 143.00
    5. ‚Üí Investigate if this feature causes false positives for benign URLs
```

---

## üîß Corrective Actions

### For High-Confidence Misclassifications:

1. **Feature Engineering**
   - Check if top SHAP features make sense
   - Consider feature interactions
   - Add domain-specific features

2. **Data Rebalancing**
   - Check class distribution in training data
   - Use SMOTE or undersampling
   - Adjust class weights

3. **Model Tuning**
   - Adjust base model hyperparameters
   - Tune meta-layer fusion weights
   - Try different ensemble strategies

### For Low-Confidence Misclassifications:

1. **Probability Thresholds**
   - Add "uncertain" category for low confidence
   - Require higher confidence for sensitive classes
   - Use probability calibration

2. **Feature Selection**
   - Remove noisy features
   - Focus on most discriminative features
   - Use feature importance from SHAP

---

## üìà Example Workflow

### Debugging a Specific URL

```python
from hsef_debugger import HSEFDebugger
import pandas as pd

# 1. Initialize debugger
debugger = HSEFDebugger()

# 2. Load the problematic URL
df = pd.read_csv('All.csv')
url_row = df[df['URL_Type_obf_Type'] == 'benign'].sample(1).iloc[0]
features = url_row.drop('URL_Type_obf_Type')
actual = url_row['URL_Type_obf_Type']

# 3. Analyze
result = debugger.analyze_url(features, "problematic_url", actual)

# 4. Check if misclassified
if result['predicted_class'] != actual:
    # 5. Examine insights
    insights = result['misclassification_analysis']['insights']
    for insight in insights:
        print(insight)
    
    # 6. Check SHAP features
    top_features = result['shap_analysis']['top_features'][:5]
    for feat in top_features:
        print(f"{feat['feature']}: {feat['value']}")
    
    # 7. Review visualization
    print(f"Check: debug_results/debug_analysis_problematic_url_*.png")
```

### Finding Systematic Issues

```python
# Analyze a batch
results = debugger.analyze_csv('test_batch.csv')

# Find common patterns in misclassifications
misclassified = [r for r in results 
                 if r.get('misclassification_analysis', {}).get('is_misclassified')]

# Analyze which base model is most often wrong
rf_wrong = sum(1 for r in misclassified 
               if 'Random Forest' in r['misclassification_analysis']['base_model_agreement'])
xgb_wrong = sum(1 for r in misclassified 
                if 'XGBoost' in r['misclassification_analysis']['base_model_agreement'])
svm_wrong = sum(1 for r in misclassified 
                if 'SVM' in r['misclassification_analysis']['base_model_agreement'])

print(f"Random Forest wrong: {rf_wrong}/{len(misclassified)}")
print(f"XGBoost wrong: {xgb_wrong}/{len(misclassified)}")
print(f"SVM wrong: {svm_wrong}/{len(misclassified)}")
```

---

## üé® Visualization Guide

The 4-panel plot includes:

1. **Top-Left: Base Model Predictions**
   - Horizontal bars showing confidence
   - Green = agrees with final
   - Red = disagrees with final
   - Labels show predicted class

2. **Top-Right: Meta-Layer Contributions**
   - Shows fusion weights
   - Blue = positive contribution
   - Orange = negative contribution
   - Values show exact contribution scores

3. **Bottom-Left: Class Probabilities**
   - Final ensemble probabilities
   - Green = predicted class
   - Gray = other classes
   - Shows percentage on each bar

4. **Bottom-Right: SHAP Feature Importance**
   - Top 8 features
   - Red = pushed toward prediction
   - Blue = pushed away
   - Values show SHAP impact

---

## üí° Tips & Best Practices

1. **Always provide actual_class when available**
   - Enables misclassification analysis
   - Provides corrective insights

2. **Run batch analysis for patterns**
   - Individual URLs may be outliers
   - Batch reveals systematic issues

3. **Focus on high-confidence errors**
   - These indicate systematic problems
   - Low-confidence errors may just be uncertain cases

4. **Use SHAP features for debugging**
   - Shows exactly what drove the decision
   - Helps identify problematic features

5. **Compare base models**
   - If all agree and wrong = feature problem
   - If split = fusion weight problem

---

## üêõ Troubleshooting

**"SHAP not available"**
```bash
pip install shap
```

**"Model not loaded"**
- Make sure `models/` directory exists
- Run `python quick_setup.py` first

**"Feature mismatch"**
- Ensure CSV has same features as training data
- Check feature names match exactly

**Slow SHAP analysis**
- Reduce background sample size in `_initialize_shap()`
- Use smaller dataset for analysis

---

## üìö Integration with Web App

You can add debugging to the web interface:

```python
# In app.py, add a debug endpoint
@app.route('/api/debug_prediction', methods=['POST'])
def debug_prediction():
    from hsef_debugger import HSEFDebugger
    
    data = request.get_json()
    url_features = data.get('features')
    
    debugger = HSEFDebugger()
    result = debugger.analyze_url(url_features, "web_request")
    
    return jsonify(result)
```

---

## ‚úÖ Complete Example Output

When you run `python example_debugger.py`, you'll see:

```
‚úì Loaded stacking model
‚úì Loaded scaler
‚úì Loaded metadata: 79 features, 5 classes
‚úì Extracted base models
‚úì SHAP explainer initialized

ANALYZING: Example_URL_1
======================================================================

1Ô∏è‚É£  BASE MODEL PREDICTIONS
----------------------------------------------------------------------
Random Forest:
  Predicted: spam
  Confidence: 99.52%
  ...

2Ô∏è‚É£  META-LAYER FUSION ANALYSIS
----------------------------------------------------------------------
Meta-Layer Fusion Weights:
Contributions to predicted class 'spam':
  Random Forest  : +0.3421
  ...

3Ô∏è‚É£  FINAL ENSEMBLE PREDICTION
----------------------------------------------------------------------
Predicted Class: spam
Confidence: 99.88%
...

4Ô∏è‚É£  SHAP FEATURE IMPORTANCE ANALYSIS
----------------------------------------------------------------------
Top 10 Most Important Features:
  urlLen          : +0.012453  ‚Üí spam
  ...

‚úì Saved visualization: debug_results/debug_analysis_Example_URL_1_*.png
‚úì Saved JSON report: debug_results/debug_report_Example_URL_1_*.json
‚úì Saved CSV summary: debug_results/debug_summary_Example_URL_1_*.csv
```

---

**Your HSEF debugger is ready to use! Run `python example_debugger.py` to see it in action!** üéâ
